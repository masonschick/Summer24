{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Installs and Imports\n","import requests\n","from bs4 import BeautifulSoup\n","import random\n","import time\n","from itertools import cycle"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Request failed: HTTPSConnectionPool(host='sportsbook.draftkings.com', port=443): Max retries exceeded with url: / (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 400 Bad Request')))\n","Request failed: HTTPSConnectionPool(host='sportsbook.draftkings.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1006)')))\n"]}],"source":["\n","# List of user agents\n","user_agents = [\n","    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n","    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:55.0) Gecko/20100101 Firefox/55.0\",\n","    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\"\n","]\n","\n","# List of proxy servers\n","proxies = [\n","    \"http://138.68.60.8:8080\",\n","    \"http://51.210.164.122:8080\",\n","    \"http://163.5.194.26:80\"\n","]\n","\n","proxy_pool = cycle(proxies)\n","\n","# URL of the website you want to scrape\n","url = \"https://sportsbook.draftkings.com/\"\n","\n","def get_html(url, headers, proxy):\n","    try:\n","        response = requests.get(url, headers=headers, proxies={\"http\": proxy, \"https\": proxy})\n","        if response.status_code == 200:\n","            return response.content\n","        else:\n","            print(f\"Failed to retrieve content: {response.status_code}\")\n","            return None\n","    except requests.RequestException as e:\n","        print(f\"Request failed: {e}\")\n","        return None\n","\n","# Main scraping loop\n","for _ in range(10):  # Adjust the range based on how many times you want to iterate\n","    # Choose a random user agent\n","    user_agent = random.choice(user_agents)\n","    headers = {\"User-Agent\": user_agent}\n","    \n","    # Get a proxy from the pool\n","    proxy = next(proxy_pool)\n","    \n","    # Get the HTML content\n","    html_content = get_html(url, headers, proxy)\n","    \n","    if html_content:\n","        # Parse the HTML content\n","        soup = BeautifulSoup(html_content, 'html.parser')\n","        \n","        # Example: Find all elements with a specific tag or class\n","        data = soup.find_all('div', class_='sportsbook-event-accordion__wrapper')\n","        \n","        # Extract and print the desired information\n","        for item in data:\n","            print(item.text)\n","            \n","    else:\n","        # Stop execution if an error occurs\n","        break\n","    \n","    # Wait for a random period to avoid detection\n","    time.sleep(random.uniform(5, 15))"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
